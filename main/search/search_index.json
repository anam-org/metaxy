{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Metaxy \ud83c\udf0c","text":"<p>Metaxy is a feature metadata management system for ML pipelines that tracks feature versions, dependencies, and data lineage across complex computation graphs. Metaxy supports incremental computations, sample-level versioning, field-level versioning, and more.</p> <p>Metaxy is:</p> <ul> <li> <p>\ud83e\udde9 composable --- bring your own everything!</p> <ul> <li>supports DuckDB, ClickHouse, and 20+ databases via Ibis</li> <li>supports lakehouse storage formats such as DeltaLake or DuckLake</li> <li>is agnostic to tabular compute engines: Polars, Spark, Pandas, and databases thanks to Narwhals</li> <li>we totally don't care how is the multi-modal data produced or where is it stored: Metaxy is responsible for yielding input metadata and writing output metadata</li> </ul> </li> <li> <p>\ud83e\udea8 rock solid where it matters:</p> <ul> <li>data versioning is guaranteed to be consistent across DBs or in-memory compute engines. We really have tested this very well!</li> <li>changes to topology, feature versioning, or individual samples ruthlessly propagate downstream</li> <li>unique field-level dependency system prevents unnecessary recomputations for features that depend on partial data</li> <li>metadata is append-only to ensure data integrity and immutability. Users can perform cleanup if needed (Metaxy provides tools for this).</li> </ul> </li> <li> <p>\ud83e\udd38 flexible to work around restrictions consciously:</p> <ul> <li>has a migrations system to compensate for reconciling data versions and metadata when computations are not desired</li> </ul> </li> <li> <p>\ud83d\udcc8 scalable:</p> <ul> <li>supports feature organization and discovery patterns such as packaging entry points. This enables collaboration across teams and projects.</li> <li>is built with performance in mind: all operations default to run in the DB, Metaxy does not stand in the way of metadata flow</li> </ul> </li> <li> <p>\ud83e\uddd1\u200d\ud83d\udcbb dev friendly:</p> <ul> <li>clean, intuitive Python API that stays out of your way when you don't need it</li> <li>feature discovery system for effortless dependency management</li> <li>comprehensive type hints and Pydantic integration for excellent IDE support</li> <li>first-class support for local development, testing, preview environments, CI/CD</li> <li>CLI tool for easy interaction, inspection and visualization of feature graphs, enriched with real metadata and stats</li> <li>integrations with popular tools such as SQLModel, Dagster, and Ray.</li> <li>testing helpers that you're going to appreciate</li> </ul> </li> </ul>"},{"location":"#feature-dependencies","title":"Feature Dependencies","text":"<p>Features form a DAG where each feature declares its upstream dependencies. Consider an video processing pipeline:</p> <pre><code>class Video(Feature, spec=FeatureSpec(\n    key=\"video\",\n    fields=[\n        FieldSpec(name=\"frames\", code_version=1),\n        FieldSpec(name=\"audio\", code_version=1),\n    ],\n)):\n    path: str = Field(description=\"Path to the video file\")\n    duration: float = Field(description=\"Duration of the video in seconds\")\n\nclass VoiceDetection(Feature, spec=FeatureSpec(\n    key=\"voice_detection\",\n    deps=[FeatureDep(key=Video.spec.key)],\n)):\n    path: str = Field(description=\"Path to the voice detection json file\")\n</code></pre> <p>Note</p> <p>This API will be improved with more ergonomic alternatives. See issue #70 for details.</p> <p>When <code>Video</code> changes, Metaxy automatically identifies that <code>VoiceDetection</code> requires recomputation.</p>"},{"location":"#versioned-change-propagation","title":"Versioned Change Propagation","text":"<p>Every feature definition produces a deterministic version hash computed from its dependencies, fields, and code versions. When you modify a feature\u2014whether changing its dependencies, adding fields, or updating transformation logic, Metaxy detects the change and propagates it downstream. This is done on multiple levels: <code>Feature</code> (class) level, field (class attribute) level, and of course on row level: each sample in the metadata store tracks the version of each field and the overall (class-level) feature version.</p> <p>This ensures that when feature definitions evolve, every feature that transitively depends on it can be systematically updated. Because Metaxy supports declaring dependencies on fields, it can identify when a feature does not require recomputation, even if one of its parents has been changed (but only irrelevant fields did). This is a huge factor in improving efficiency and reducing unnecessary computations (and costs!).</p> <p>Because Metaxy feature graphs are static, Metaxy can calculate data version changes ahead of the actual computation. This enables patterns such as computation preview and computation cost prediction.</p>"},{"location":"#typical-user-workflow","title":"Typical User Workflow","text":"<ol> <li>Record Metaxy feature graph in CI/CD (not necessary in non-production environments)</li> </ol> <pre><code>metaxy graph push\n</code></pre> <ol> <li>Use <code>metaxy.MetadataStore.resolve_update</code> to identify samples requiring recomputation:</li> </ol> <pre><code>from metaxy import load_features\n\n# discover and load Metaxy features\nload_features()\n\nstore = ...  # can be DuckDBMetadataStore locally and ClickHouseMetadataStore in production\ndiff = store.resolve_update(VoiceDetection)\n</code></pre> <p><code>metaxy.MetadataStore.resolve_update</code> runs in the database unless it doesn't support the required hash functions, otherwise it fallbacks to in-memory Polars computation (results are guaranteed to be consistent). The returned object provides Narwhals (backend-agnostic) DataFrames with all the data versions already computed.</p> <ol> <li>Handle the computation, this is entirely user-defined, Metaxy is not involved in this step.</li> </ol> <pre><code>if (len(diff.added) + len(diff.changed)) &gt; 0:\n    # run your computation, this can be done in a distributed manner\n    results = run_voice_detection(diff, ...)\n</code></pre> <ol> <li>Record metadata for computed samples, this can be done in a distributed manner as well</li> </ol> <pre><code>    store.write_metadata(VoiceDetection, results)\n</code></pre> <p>We have successfully recorded the metadata for the computed samples.</p> <p>No Uniqueness Checks!</p> <p>Metaxy doesn't attempt to perform any deduplication or uniqueness checks for performance reasons. While <code>MetadataStore.resolve_update</code> is guaranteed to never return the same versioned sample twice (hey that's the whole point of Metaxy), it's up to the user to ensure that samples are not written multiple times to the metadata store. Configuring deduplication or uniqueness checks in the store (database) is a good idea.</p>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li>Learn more about Data Versioning</li> <li>Take a look at CLI reference</li> </ul>"},{"location":"learn/data-versioning/","title":"Data Versioning","text":"<p>Metaxy computes data versions as hashes of upstream dependencies, enabling automatic change detection and incremental computation.</p>"},{"location":"learn/data-versioning/#how-it-works","title":"How It Works","text":"<p>Consider a video processing pipeline with these features:</p> <pre><code>from metaxy import Feature, FeatureDep, FeatureKey, FeatureSpec, FieldDep, FieldKey, FieldSpec\n\nclass Video(\n    Feature,\n    spec=FeatureSpec(\n        key=FeatureKey([\"example\", \"video\"]),\n        deps=None,  # Root feature\n        fields=[\n            FieldSpec(key=FieldKey([\"audio\"]), code_version=1),\n            FieldSpec(key=FieldKey([\"frames\"]), code_version=1),\n        ],\n    ),\n):\n    \"\"\"Video metadata feature (root).\"\"\"\n    frames: int\n    duration: float\n    size: int\n\n\nclass Crop(\n    Feature,\n    spec=FeatureSpec(\n        key=FeatureKey([\"example\", \"crop\"]),\n        deps=[FeatureDep(key=Video.spec.key)],\n        fields=[\n            FieldSpec(\n                key=FieldKey([\"audio\"]),\n                code_version=1,\n                deps=[FieldDep(feature_key=Video.spec.key, fields=[FieldKey([\"audio\"])])],\n            ),\n            FieldSpec(\n                key=FieldKey([\"frames\"]),\n                code_version=1,\n                deps=[FieldDep(feature_key=Video.spec.key, fields=[FieldKey([\"frames\"])])],\n            ),\n        ],\n    ),\n):\n    pass\n\n\nclass FaceDetection(\n    Feature,\n    spec=FeatureSpec(\n        key=FeatureKey([\"example\", \"face_detection\"]),\n        deps=[FeatureDep(key=Crop.spec.key)],\n        fields=[\n            FieldSpec(\n                key=FieldKey([\"faces\"]),\n                code_version=1,\n                deps=[FieldDep(feature_key=Crop.spec.key, fields=[FieldKey([\"frames\"])])],\n            ),\n        ],\n    ),\n):\n    pass\n\n\nclass SpeechToText(\n    Feature,\n    spec=FeatureSpec(\n        key=FeatureKey([\"example\", \"stt\"]),\n        deps=[FeatureDep(key=Video.spec.key)],\n        fields=[\n            FieldSpec(\n                key=FieldKey([\"transcription\"]),\n                code_version=1,\n                deps=[FieldDep(feature_key=Video.spec.key, fields=[FieldKey([\"audio\"])])],\n            ),\n        ],\n    ),\n):\n    pass\n</code></pre> <p>Running <code>metaxy graph render --format mermaid</code> produces this graph:</p> <pre><code>---\ntitle: Feature Graph\n---\nflowchart TB\n    %% Snapshot version: 8468950d\n    %%{init: {'flowchart': {'htmlLabels': true, 'curve': 'basis'}, 'themeVariables': {'fontSize': '14px'}}}%%\n        example_video[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/video&lt;/b&gt;&lt;br/&gt;&lt;small&gt;(v: bc9ca835)&lt;/small&gt;&lt;br/&gt;&lt;font\ncolor=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;\u2022 audio &lt;small&gt;(v: 22742381)&lt;/small&gt;&lt;br/&gt;\u2022 frames &lt;small&gt;(v: 794116a9)&lt;/small&gt;&lt;/div&gt;\"]\n        example_crop[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/crop&lt;/b&gt;&lt;br/&gt;&lt;small&gt;(v: 3ac04df8)&lt;/small&gt;&lt;br/&gt;&lt;font\ncolor=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;\u2022 audio &lt;small&gt;(v: 76c8bdc9)&lt;/small&gt;&lt;br/&gt;\u2022 frames &lt;small&gt;(v: abc79017)&lt;/small&gt;&lt;/div&gt;\"]\n        example_face_detection[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/face_detection&lt;/b&gt;&lt;br/&gt;&lt;small&gt;(v: 1ac83b07)&lt;/small&gt;&lt;br/&gt;&lt;font\ncolor=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;\u2022 faces &lt;small&gt;(v: 2d75f0bd)&lt;/small&gt;&lt;/div&gt;\"]\n        example_stt[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/stt&lt;/b&gt;&lt;br/&gt;&lt;small&gt;(v: c83a754a)&lt;/small&gt;&lt;br/&gt;&lt;font\ncolor=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;\u2022 transcription &lt;small&gt;(v: ac412b3c)&lt;/small&gt;&lt;/div&gt;\"]\n        example_video --&gt; example_crop\n        example_crop --&gt; example_face_detection\n        example_video --&gt; example_stt</code></pre>"},{"location":"learn/data-versioning/#tracking-changes","title":"Tracking Changes","text":"<p>Imagine the <code>audio</code> field of the <code>Video</code> feature changes (perhaps denoising was applied):</p> <pre><code>         key=FeatureKey([\"example\", \"video\"]),\n         deps=None,\n         fields=[\n             FieldSpec(\n                 key=FieldKey([\"audio\"]),\n-                code_version=1,\n+                code_version=2,\n             ),\n</code></pre> <p>Run <code>metaxy graph diff</code> to see what changed:</p> <pre><code>---\ntitle: Merged Graph Diff\n---\nflowchart TB\n    %%{init: {'flowchart': {'htmlLabels': true, 'curve': 'basis'}, 'themeVariables': {'fontSize': '14px'}}}%%\n\n    example_video[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/video&lt;/b&gt;&lt;br/&gt;&lt;font color=\"#CC0000\"&gt;bc9ca8&lt;/font&gt; \u2192 &lt;font\ncolor=\"#00AA00\"&gt;6db302&lt;/font&gt;&lt;br/&gt;&lt;font color=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;- &lt;font color=\"#FFAA00\"&gt;audio&lt;/font&gt; (&lt;font\ncolor=\"#CC0000\"&gt;227423&lt;/font&gt; \u2192 &lt;font color=\"#00AA00\"&gt;09c839&lt;/font&gt;)&lt;br/&gt;- frames (794116)&lt;/div&gt;\"]\n    style example_video stroke:#FFA500,stroke-width:3px\n    example_crop[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/crop&lt;/b&gt;&lt;br/&gt;&lt;font color=\"#CC0000\"&gt;3ac04d&lt;/font&gt; \u2192 &lt;font\ncolor=\"#00AA00\"&gt;54dc7f&lt;/font&gt;&lt;br/&gt;&lt;font color=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;- &lt;font color=\"#FFAA00\"&gt;audio&lt;/font&gt; (&lt;font\ncolor=\"#CC0000\"&gt;76c8bd&lt;/font&gt; \u2192 &lt;font color=\"#00AA00\"&gt;f3130c&lt;/font&gt;)&lt;br/&gt;- frames (abc790)&lt;/div&gt;\"]\n    style example_crop stroke:#FFA500,stroke-width:3px\n    example_face_detection[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/face_detection&lt;/b&gt;&lt;br/&gt;1ac83b&lt;br/&gt;&lt;font\ncolor=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;- faces (2d75f0)&lt;/div&gt;\"]\n    example_stt[\"&lt;div style=\"text-align:left\"&gt;&lt;b&gt;example/stt&lt;/b&gt;&lt;br/&gt;&lt;font color=\"#CC0000\"&gt;c83a75&lt;/font&gt; \u2192 &lt;font\ncolor=\"#00AA00\"&gt;066d34&lt;/font&gt;&lt;br/&gt;&lt;font color=\"#999\"&gt;---&lt;/font&gt;&lt;br/&gt;- &lt;font color=\"#FFAA00\"&gt;transcription&lt;/font&gt; (&lt;font\ncolor=\"#CC0000\"&gt;ac412b&lt;/font&gt; \u2192 &lt;font color=\"#00AA00\"&gt;058410&lt;/font&gt;)&lt;/div&gt;\"]\n    style example_stt stroke:#FFA500,stroke-width:3px\n\n    example_video --&gt; example_crop\n    example_crop --&gt; example_face_detection\n    example_video --&gt; example_stt</code></pre> <p>Notice:</p> <ul> <li><code>Video</code>, <code>Crop</code>, and <code>SpeechToText</code> changed (highlighted)</li> <li><code>FaceDetection</code> remained unchanged (depends only on <code>frames</code>, not <code>audio</code>)</li> <li>Audio field versions changed throughout the graph</li> <li>Frame field versions stayed the same</li> </ul> <p>Metaxy's static graph analysis identifies features out of sync after topology changes or code version bumps. Beyond feature and field-level versions, Metaxy computes sample-level versions ahead of computation through the entire graph, enabling processing cost prediction and automatic migrations.</p>"},{"location":"learn/data-versioning/#sample-level-versioning","title":"Sample-Level Versioning","text":"<p>For each sample (row) in your dataset, Metaxy computes a data version by hashing upstream dependency versions. This happens before the actual computation.</p> <p>Example metadata row:</p> <pre><code>{\n    \"sample_uid\": \"video_001\",\n    \"data_version\": {\n        \"audio\": \"a2ha72a\",\n        \"frames\": \"ja812hp\",\n    },\n    \"feature_version\": \"nasdh1a\",\n    \"snapshot_version\": \"def456\",\n    # User columns\n    \"path\": \"/data/video_001.mp4\",\n    \"duration\": 120.5,\n}\n</code></pre> <p>When upstream dependencies change, Metaxy recalculates data versions and identifies which samples need recomputation by comparing old versus new versions.</p>"},{"location":"learn/data-versioning/#incremental-computation","title":"Incremental Computation","text":"<p>The metadata store's <code>calculate_and_write_data_versions()</code> method:</p> <ol> <li>Joins upstream feature metadata</li> <li>Computes data version hashes for each sample</li> <li>Compares against existing metadata</li> <li>Returns diff: added, changed, removed samples</li> </ol> <p>Your pipeline processes only the samples that changed:</p> <pre><code>with store:  # MetadataStore\n    # Metaxy computes data_version and identifies changes\n    diff = store.resolve_update(MyFeature)\n\n    # Process only changed samples\n</code></pre> <p>This approach avoids expensive recomputation when nothing changed, while ensuring correctness when dependencies update.</p>"},{"location":"learn/data-versioning/#version-vs-data-version","title":"Version vs Data Version","text":"<p>Feature version: Hash of feature definition (code, deps, fields). Static, deterministic from code.</p> <p>Data version: Hash of upstream data versions for a specific sample. Depends on actual data.</p> <p>Snapshot version: Hash of all feature versions in the graph. Represents entire graph state.</p> <p>A feature version change doesn't necessarily mean all samples need recomputation. Metaxy compares data versions to identify only the affected samples.</p>"},{"location":"learn/feature-discovery/","title":"Feature Discovery","text":"<p>Metaxy provides automatic feature discovery through Python's entrypoint system. This enables modular architecture patterns essential for scaling Metaxy projects.</p>"},{"location":"learn/feature-discovery/#why-feature-discovery","title":"Why Feature Discovery?","text":"<p>Manual feature registration doesn't scale. As your system grows, you need:</p> <ul> <li>Plugin architectures - Third-party teams contribute features without modifying core code</li> <li>Feature collections - Package and distribute related features as installable units</li> <li>Monorepo support - Discover features across multiple packages in a monorepo</li> <li>Internal packages - Share features between projects via private package registries</li> </ul> <p>Feature discovery solves these problems through automatic registration at import time.</p>"},{"location":"learn/feature-discovery/#package-entry-points","title":"Package Entry Points","text":"<p>The most powerful discovery mechanism uses Python's standard entry point system via <code>project.entry-points.\"metaxy.features\"</code> in <code>pyproject.toml</code>.</p>"},{"location":"learn/feature-discovery/#creating-a-feature-plugin","title":"Creating a Feature Plugin","text":"<p>Structure your feature package:</p> <pre><code>my-video-features/\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 my_video_features/\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 detection.py\n        \u2514\u2500\u2500 transcription.py\n</code></pre> <p>Declare entry points in <code>pyproject.toml</code>:</p> <pre><code>[project]\nname = \"my-video-features\"\nversion = \"1.0.0\"\ndependencies = [\"metaxy\"]\n\n[project.entry-points.\"metaxy.features\"]\ndetection = \"my_video_features.detection\"\ntranscription = \"my_video_features.transcription\"\n</code></pre> <p>Define features in the modules:</p> <pre><code># my_video_features/detection.py\nfrom metaxy import Feature, FeatureSpec, FeatureKey\n\nclass FaceDetection(Feature, spec=FeatureSpec(\n    key=FeatureKey([\"video\", \"face_detection\"]),\n    # ... spec details\n)):\n    pass\n\nclass ObjectDetection(Feature, spec=FeatureSpec(\n    key=FeatureKey([\"video\", \"object_detection\"]),\n    # ... spec details\n)):\n    pass\n</code></pre>"},{"location":"learn/feature-discovery/#installing-and-using-plugins","title":"Installing and Using Plugins","text":"<p>Install the package:</p> <pre><code>pip install my-video-features\n# Or in a monorepo:\npip install -e ./packages/my-video-features\n</code></pre> <p>UV Package Manager: Entry Point Changes</p> <p>If you're using <code>uv</code> and modify entry points in <code>pyproject.toml</code>, <code>uv sync</code> will not recreate the editable package metadata. You must explicitly reinstall:</p> <pre><code>uv sync --reinstall-package my-video-features\n</code></pre> <p>Installed features will be automatically discovered and loaded:</p> <pre><code>from metaxy import load_features\n\n# Automatically discovers and loads all features\n# from installed packages with metaxy.features entry points\nload_features()\n\n# Features are now available in the global graph\nfrom metaxy import FeatureGraph\ngraph = FeatureGraph.get_active()\nprint(f\"Loaded {len(graph.features_by_key)} features\")\n</code></pre>"},{"location":"learn/feature-discovery/#monorepo-patterns","title":"Monorepo Patterns","text":"<p>In monorepos, use entry points to manage feature collections across teams:</p>"},{"location":"learn/feature-discovery/#team-owned-feature-packages","title":"Team-Owned Feature Packages","text":"<pre><code>monorepo/\n\u251c\u2500\u2500 packages/\n\u2502   \u251c\u2500\u2500 core-features/\n\u2502   \u2502   \u2514\u2500\u2500 pyproject.toml  # [project.entry-points.\"metaxy.features\"]\n\u2502   \u251c\u2500\u2500 ml-features/\n\u2502   \u2502   \u2514\u2500\u2500 pyproject.toml  # [project.entry-points.\"metaxy.features\"]\n\u2502   \u2514\u2500\u2500 experimental-features/\n\u2502       \u2514\u2500\u2500 pyproject.toml  # [project.entry-points.\"metaxy.features\"]\n\u2514\u2500\u2500 apps/\n    \u2514\u2500\u2500 main-pipeline/\n        \u2514\u2500\u2500 pyproject.toml  # depends on feature packages\n</code></pre> <p>Each team maintains their features independently:</p> <pre><code># packages/ml-features/pyproject.toml\n[project.entry-points.\"metaxy.features\"]\nembeddings = \"ml_features.embeddings\"\nclassifiers = \"ml_features.classifiers\"\n</code></pre> <p>The main application discovers all features.</p>"},{"location":"learn/feature-discovery/#config-based-discovery","title":"Config-Based Discovery","text":"<p>For simpler use cases, load features directly from module paths specified in Metaxy configuration:</p> metaxy.tomlpyproject.toml <pre><code>entrypoints = [\n    \"myapp.features.video\",\n]\n</code></pre> <pre><code>[tool.metaxy]\nentrypoints = [\n    \"myapp.features.video\",\n]\n</code></pre> <pre><code>from metaxy import load_features\n\n# Discovers features from configured entrypoints\nload_features()\n</code></pre>"},{"location":"learn/feature-discovery/#best-practices","title":"Best Practices","text":"<ol> <li>Use entry points for distribution - Any features intended for reuse should use entry points</li> <li>Version your feature packages - Use semantic versioning for feature collections</li> <li>Test in isolation - Load feature packages into test graphs to verify behavior</li> </ol> <p>The entry point system transforms feature management from a manual process to an automatic, scalable system that grows with your organization.</p>"},{"location":"learn/testing/","title":"Testing Metaxy Features","text":"<p>This guide covers patterns for testing your features when using Metaxy.</p>"},{"location":"learn/testing/#graph-isolation","title":"Graph Isolation","text":"<p>By default, Metaxy uses a single global feature graph where all features register themselves automatically. In testing, you need isolated graphs to prevent test interference.</p>"},{"location":"learn/testing/#using-isolated-graphs","title":"Using Isolated Graphs","text":"<p>Always use isolated graphs in tests:</p> <pre><code>def test_my_feature():\n    test_graph = FeatureGraph()\n    with test_graph.use():\n        class MyFeature(Feature, spec=...):\n            pass\n        # Test operations here\n</code></pre> <p>The context manager ensures all feature registrations within the block use the test graph instead of the global one.</p>"},{"location":"learn/testing/#graph-context-management","title":"Graph Context Management","text":"<p>The active graph uses context variables to support multiple graphs:</p> <pre><code># Default global graph (used in production)\ngraph = FeatureGraph()\n\n# Get active graph\nactive = FeatureGraph.get_active()\n\n# Use custom graph temporarily\nwith custom_graph.use():\n    # All operations use custom_graph\n    pass\n</code></pre> <p>This enables:</p> <ul> <li>Isolated testing: Each test gets its own feature registry</li> <li>Migration testing: Load historical graphs for migration scenarios</li> <li>Multi-environment testing: Test different feature configurations</li> </ul>"},{"location":"learn/testing/#testing-metadata-store-operations","title":"Testing Metadata Store Operations","text":""},{"location":"learn/testing/#context-manager-pattern","title":"Context Manager Pattern","text":"<p>Stores must be used as context managers to ensure proper resource cleanup:</p> <pre><code>def test_metadata_operations():\n    with InMemoryMetadataStore() as store:\n        # Create test data\n        df = pl.DataFrame({\n            \"sample_uid\": [1, 2, 3],\n            \"data_version\": {...},\n            \"feature_version\": \"abc123\"\n        })\n\n        # Write metadata\n        store.write_metadata(MyFeature, df)\n\n        # Read and verify\n        result = store.read_metadata(MyFeature)\n        assert len(result) == 3\n</code></pre>"},{"location":"learn/testing/#testing-with-different-backends","title":"Testing with Different Backends","text":"<p>Use parametrized tests to verify behavior across backends:</p> <pre><code>import pytest\n\n@pytest.mark.parametrize(\"store_cls\", [\n    InMemoryMetadataStore,\n    DuckDBMetadataStore,\n    SQLiteMetadataStore,\n])\ndef test_store_behavior(store_cls, tmp_path):\n    # Use tmp_path for file-based stores\n    store_kwargs = {}\n    if store_cls != InMemoryMetadataStore:\n        store_kwargs[\"path\"] = tmp_path / \"test.db\"\n\n    with store_cls(**store_kwargs) as store:\n        # Test your feature operations\n        pass\n</code></pre>"},{"location":"learn/testing/#testing-custom-alignment","title":"Testing Custom Alignment","text":"<p>If your feature overrides <code>load_input()</code> for custom alignment, test it thoroughly:</p> <pre><code>def test_custom_alignment():\n    # Prepare test data\n    current = pl.DataFrame({\n        \"sample_uid\": [1, 2, 3],\n        \"custom_field\": [\"a\", \"b\", \"c\"]\n    })\n\n    upstream = {\n        \"video_feature\": pl.DataFrame({\n            \"sample_uid\": [2, 3, 4],\n            \"data_version\": {...}\n        })\n    }\n\n    # Test alignment logic\n    result = MyFeature.load_input(current, upstream)\n\n    # Verify behavior\n    assert set(result[\"sample_uid\"].to_list()) == {2, 3}  # Inner join\n    assert \"custom_field\" in result.columns  # Custom fields preserved\n</code></pre>"},{"location":"learn/testing/#testing-feature-dependencies","title":"Testing Feature Dependencies","text":"<p>Verify that dependencies are correctly defined:</p> <pre><code>def test_feature_dependencies():\n    test_graph = FeatureGraph()\n\n    with test_graph.use():\n        # Define upstream feature\n        class UpstreamFeature(Feature, spec=FeatureSpec(\n            key=FeatureKey([\"upstream\"]),\n            fields=[FieldSpec(key=FieldKey([\"data\"]), code_version=1)]\n        )):\n            pass\n\n        # Define downstream feature with dependency\n        class DownstreamFeature(Feature, spec=FeatureSpec(\n            key=FeatureKey([\"downstream\"]),\n            deps=[FeatureDep(key=FeatureKey([\"upstream\"]))],\n            fields=[\n                FieldSpec(\n                    key=FieldKey([\"processed\"]),\n                    code_version=1,\n                    deps=[FieldDep(\n                        feature_key=FeatureKey([\"upstream\"]),\n                        fields=[FieldKey([\"data\"])]\n                    )]\n                )\n            ]\n        )):\n            pass\n\n        # Verify graph structure\n        assert len(test_graph.features_by_key) == 2\n        assert UpstreamFeature in test_graph.get_downstream(DownstreamFeature)\n</code></pre>"},{"location":"learn/testing/#testing-migrations","title":"Testing Migrations","text":""},{"location":"learn/testing/#simulating-feature-changes","title":"Simulating Feature Changes","text":"<p>Test how your features behave when definitions change:</p> <pre><code>def test_migration_scenario():\n    # Initial version\n    graph_v1 = FeatureGraph()\n    with graph_v1.use():\n        class MyFeatureV1(Feature, spec=FeatureSpec(\n            key=FeatureKey([\"my_feature\"]),\n            fields=[FieldSpec(key=FieldKey([\"field1\"]), code_version=1)]\n        )):\n            pass\n\n    # Record initial state\n    with InMemoryMetadataStore() as store:\n        store.record_feature_graph_snapshot(graph_v1)\n\n        # Modified version\n        graph_v2 = FeatureGraph()\n        with graph_v2.use():\n            class MyFeatureV2(Feature, spec=FeatureSpec(\n                key=FeatureKey([\"my_feature\"]),\n                fields=[FieldSpec(key=FieldKey([\"field1\"]), code_version=2)]\n            )):\n                pass\n\n        # Verify version change detected\n        with graph_v2.use():\n            changes = store.detect_feature_changes(MyFeatureV2)\n            assert changes is not None\n</code></pre>"},{"location":"learn/testing/#testing-migration-idempotency","title":"Testing Migration Idempotency","text":"<p>Ensure migrations can be safely re-run:</p> <pre><code>def test_migration_idempotency():\n    with InMemoryMetadataStore() as store:\n        # Apply migration twice\n        apply_migration(store, migration)\n        result1 = store.read_metadata(MyFeature)\n\n        apply_migration(store, migration)  # Should be no-op\n        result2 = store.read_metadata(MyFeature)\n\n        # Results should be identical\n        assert result1.equals(result2)\n</code></pre>"},{"location":"learn/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Always use isolated graphs - Never rely on the global graph in tests</li> <li>Use context managers - Ensure proper cleanup of stores and resources</li> <li>Test across backends - Verify features work with different metadata stores</li> <li>Test edge cases - Empty data, missing dependencies, version conflicts</li> <li>Mock external dependencies - Isolate tests from external services</li> <li>Verify determinism - Feature versions should be consistent across runs</li> </ol>"},{"location":"learn/integrations/sqlmodel/","title":"SQLModel Integration","text":"<p>The SQLModel integration enables Metaxy features to function as both metadata-tracked features and SQLAlchemy ORM models. This integration combines Metaxy's versioning and dependency tracking with SQLModel's database mapping and query capabilities.</p>"},{"location":"learn/integrations/sqlmodel/#problem-statement","title":"Problem Statement","text":"<p>Multimodal ML pipelines often require persistent storage of metadata alongside versioned feature definitions. While Metaxy tracks feature versions and data lineage, SQLModel provides ORM functionality for database interactions. The integration eliminates the need to maintain separate classes for feature definitions and database models, ensuring consistency between logical feature structure and physical storage schema.</p> <p>Additionally, users can benefit from migration systems such as Alembic.</p>"},{"location":"learn/integrations/sqlmodel/#installation","title":"Installation","text":"<p>The SQLModel integration requires the sqlmodel package:</p> <pre><code>pip install metaxy[sqlmodel]\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#basic-usage","title":"Basic Usage","text":"<p>Define a feature class that inherits from <code>SQLModelFeature</code> and specify both Metaxy's <code>spec</code> parameter and SQLModel's <code>table=True</code> parameter:</p> <pre><code>from metaxy.ext.sqlmodel import SQLModelFeature\nfrom metaxy import FeatureSpec, FeatureKey, FieldSpec, FieldKey\nfrom sqlmodel import Field\n\nclass VideoFeature(\n    SQLModelFeature,\n    table=True,\n    spec=FeatureSpec(\n        key=FeatureKey([\"video\"]),\n        deps=None,  # Root feature with no dependencies\n        fields=[\n            FieldSpec(key=FieldKey([\"frames\"]), code_version=1),\n            FieldSpec(key=FieldKey([\"duration\"]), code_version=1),\n        ],\n    ),\n):\n    # Primary key\n    uid: str = Field(primary_key=True)\n\n    # Metadata columns\n    path: str\n    duration: float\n</code></pre> <p>This class serves dual purposes:</p> <ul> <li>Metaxy feature: Tracks feature version, field versions, and dependencies</li> <li>SQLModel table: Maps to database schema with ORM functionality</li> </ul> <p>Automatic Table Naming</p> <p>When <code>__tablename__</code> is not specified, it is automatically generated from the feature key. For <code>FeatureKey([\"video\"])</code>, the table name becomes <code>\"video\"</code>. For <code>FeatureKey([\"video\", \"processing\"])</code>, it becomes <code>\"video__processing\"</code>. This behavior can be disabled in Metaxy's configuration.</p>"},{"location":"learn/integrations/sqlmodel/#system-managed-columns","title":"System-Managed Columns","text":"<p>Metaxy's metadata store automatically manages versioning columns:</p> <ul> <li><code>data_version</code>: Struct column mapping field keys to hashes</li> <li><code>feature_version</code>: Hash of feature specification</li> <li><code>snapshot_version</code>: Hash of entire graph state</li> </ul> <p>These columns need not be defined in your SQLModel class. The metadata store injects them during write and read operations.</p>"},{"location":"learn/integrations/sqlmodel/#loading-features-and-populating-metadata","title":"Loading Features and Populating Metadata","text":"<p>When using <code>metaxy.load_features()</code> to discover and import feature modules, all <code>SQLModelFeature</code> classes are automatically registered in SQLModel's metadata:</p> <pre><code>from metaxy import load_features\nfrom sqlmodel import SQLModel\n\n# Load all features from configured entrypoints\ngraph = load_features()\n\n# All SQLModelFeature tables are now registered in SQLModel.metadata\n# This metadata can be used with Alembic for migrations\nprint(f\"Tables registered: {list(SQLModel.metadata.tables.keys())}\")\n</code></pre> <p>This is particularly useful when: - Generating Alembic migrations that need to discover all tables - Setting up database connections that require the complete schema - Using SQLModel's <code>create_all()</code> for development/testing (Metaxy's <code>auto_create_tables</code> setting should be preferred over <code>create_all()</code>)</p> <p>Migration Generation</p> <p>After calling <code>load_features()</code>, you can use Alembic to automatically detect all your SQLModelFeature tables and generate migration scripts.</p>"},{"location":"learn/integrations/sqlmodel/#configuration","title":"Configuration","text":"<p>Configure automatic table naming behavior:</p> metaxy.tomlpyproject.tomlEnvironment Variable <pre><code>[ext.sqlmodel]\ninfer_db_table_names = true  # Default\n</code></pre> <pre><code>[ext.sqlmodel]\ninfer_db_table_names = true  # Default\n</code></pre> <pre><code>export METAXY_EXT_SQLMODEL_INFER_DB_TABLE_NAMES=true\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#database-migrations-with-alembic","title":"Database Migrations with Alembic","text":"<p>Metaxy provides SQLModel definitions for its system tables that integrate with Alembic for database migrations. This allows you to version control schema changes alongside your application code. Note that you might want to keep separate migrations per each DB-backed <code>MetadataStore</code> used with Metaxy.</p>"},{"location":"learn/integrations/sqlmodel/#separate-migration-management","title":"Separate Migration Management","text":"<p>Metaxy system tables and user application tables should be managed in separate Alembic migration directories. This separation provides critical safety guarantees:</p> <p>System Table Isolation: Metaxy system tables (<code>metaxy-system__feature_versions</code>, <code>metaxy-system__migration_events</code>) have schemas managed by the framework. User migrations cannot accidentally modify these internal structures.</p> <p>Independent Evolution: Metaxy can evolve its system table schemas independently through framework updates without conflicts with user migrations.</p> <p>Failure Isolation: User migration failures remain isolated from metaxy's internal state tracking. A failed user migration leaves system tables intact for debugging and recovery.</p> <p>Clear Audit Trail: Separate migration histories make it trivial to distinguish framework schema changes from application schema changes. This clarity is essential during rollbacks and incident investigation.</p>"},{"location":"learn/integrations/sqlmodel/#setup","title":"Setup","text":"<p>Enable SQLModel system tables in your metaxy configuration and set up two Alembic directories:</p> <pre><code># Standard structure\nproject/\n\u251c\u2500\u2500 alembic/              # User application migrations\n\u2502   \u251c\u2500\u2500 versions/\n\u2502   \u2514\u2500\u2500 env.py\n\u251c\u2500\u2500 .metaxy/\n\u2502   \u2514\u2500\u2500 alembic-system/   # Metaxy system table migrations\n\u2502       \u251c\u2500\u2500 versions/\n\u2502       \u2514\u2500\u2500 env.py\n\u2514\u2500\u2500 metaxy.toml\n</code></pre> <p>Initialize both Alembic directories:</p> <pre><code># Initialize user migrations\nalembic init alembic\n\n# Initialize metaxy system migrations\nalembic init .metaxy/alembic-system\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#metaxy-system-tables-configuration","title":"Metaxy System Tables Configuration","text":"<p>Configure <code>.metaxy/alembic-system/env.py</code> to manage only metaxy system tables:</p> <pre><code># typical Alembic boilerplate\nfrom metaxy.ext.alembic import get_metaxy_metadata\n\nmetaxy_system_metadata = get_metaxy_metadata()\n\n# metaxy_system_metadata has system tables\n\n# continue with alembic boilerplate\n</code></pre> <p>Configure <code>.metaxy/alembic-system/alembic.ini</code> with your database URL:</p> <pre><code>[alembic]\nscript_location = .metaxy/alembic-system\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#user-application-tables-configuration","title":"User Application Tables Configuration","text":"<p>Configure <code>alembic/env.py</code> to manage user tables, excluding metaxy system tables:</p> <pre><code># standard Alembic boilerplate\nfrom sqlmodel import SQLModel\nfrom metaxy import load_features\n\nload_features()\n\n# SQLModel.metadata now has user-defined Metaxy tables\n\n\n# continue with alembic boilerplate\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#migration-workflow","title":"Migration Workflow","text":"<p>Generate and apply migrations separately for each concern:</p> <pre><code># 1. Create metaxy system tables (run once during initial setup)\nalembic -c .metaxy/alembic-system/alembic.ini revision --autogenerate -m \"create metaxy system tables\"\nalembic -c .metaxy/alembic-system/alembic.ini upgrade head\n\n# 2. Create and apply user table migrations\nalembic revision --autogenerate -m \"add video feature table\"\nalembic upgrade head\n\n# 3. When modifying user tables, only user migrations change\nalembic revision --autogenerate -m \"add processing timestamp\"\nalembic upgrade head\n</code></pre> <p>When deploying to production, always apply system table migrations before user migrations:</p> <pre><code># Production deployment order\nalembic -c .metaxy/alembic-system/alembic.ini upgrade head  # System tables first\nalembic upgrade head                                 # Then user tables\n</code></pre>"},{"location":"learn/integrations/sqlmodel/#disabling-sqlmodel-system-tables","title":"Disabling SQLModel System Tables","text":"<p>If required, disable SQLModel system tables in <code>metaxy.toml</code>:</p> <pre><code>[ext.sqlmodel]\nenabled = true\nsystem_tables = false\n</code></pre>"},{"location":"reference/cli/","title":"CLI Commands","text":"<p>This section provides a comprehensive reference for all Metaxy CLI commands.</p> <p>Metaxy - Feature Metadata Management</p>"},{"location":"reference/cli/#table-of-contents","title":"Table of Contents","text":"<ul> <li><code>shell</code></li> <li><code>migrations</code></li> <li><code>generate</code></li> <li><code>apply</code></li> <li><code>status</code></li> <li><code>list</code></li> <li><code>explain</code></li> <li><code>describe</code></li> <li><code>graph</code></li> <li><code>push</code></li> <li><code>history</code></li> <li><code>describe</code></li> <li><code>render</code></li> <li><code>graph-diff</code></li> <li><code>render</code></li> <li><code>list</code></li> <li><code>features</code></li> <li><code>metadata</code></li> <li><code>copy</code></li> <li><code>drop</code></li> </ul> <p>Usage:</p> <pre><code>$ metaxy COMMAND\n</code></pre> <p>Arguments:</p> <p>Commands:</p> <ul> <li><code>graph</code>: Manage feature graphs</li> <li><code>graph-diff</code>: Compare and visualize graph snapshots</li> <li><code>list</code>: List Metaxy entities</li> <li><code>metadata</code>: Manage Metaxy metadata</li> <li><code>migrations</code>: Metadata migration commands</li> <li><code>shell</code>: Start interactive shell.</li> </ul>"},{"location":"reference/cli/#shell","title":"<code>shell</code>","text":"<p>Start interactive shell.</p> <p>Usage:</p> <pre><code>$ shell\n</code></pre>"},{"location":"reference/cli/#migrations","title":"<code>migrations</code>","text":"<p>Metadata migration commands</p> <p>Usage:</p> <pre><code>$ migrations COMMAND\n</code></pre> <p>Commands:</p> <ul> <li><code>apply</code>: Apply migration(s) from YAML files.</li> <li><code>describe</code>: Show verbose description of migration(s).</li> <li><code>explain</code>: Show detailed diff for a migration.</li> <li><code>generate</code>: Generate migration from detected feature changes.</li> <li><code>list</code>: List all migrations in chain order.</li> <li><code>status</code>: Show migration chain and execution status.</li> </ul>"},{"location":"reference/cli/#metaxy-migrations-generate","title":"<code>metaxy migrations generate</code>","text":"<p>Generate migration from detected feature changes.</p> <p>Compares the latest snapshot in the store (or specified from_snapshot) with the current active graph to detect changes.</p> <p>The migration is recorded in the system tables (not a YAML file).</p> <p>Usage:</p> <pre><code>$ metaxy migrations generate --op LIST[STR] [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>--OP</code>: Operation class path to use (can be repeated). Example: metaxy.migrations.ops.DataVersionReconciliation  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--name</code>: Migration name (creates {timestamp}_{name} ID)</li> <li><code>--store</code>: Store name (defaults to default)</li> <li><code>--from-snapshot</code>: Compare from this historical snapshot version (defaults to latest)</li> </ul>"},{"location":"reference/cli/#metaxy-migrations-apply","title":"<code>metaxy migrations apply</code>","text":"<p>Apply migration(s) from YAML files.</p> <p>Reads migration definitions from .metaxy/migrations/ directory (git). Follows parent chain to ensure correct order.  Tracks execution state in database (events).</p> <p>Usage:</p> <pre><code>$ metaxy migrations apply [OPTIONS] [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>MIGRATION-ID, --migration-id</code>: Migration ID to apply (applies all unapplied if not specified)</li> <li><code>--dry-run, --no-dry-run</code>: Preview changes without executing  [default: --no-dry-run]</li> </ul>"},{"location":"reference/cli/#metaxy-migrations-status","title":"<code>metaxy migrations status</code>","text":"<p>Show migration chain and execution status.</p> <p>Reads migration definitions from YAML files (git). Shows execution status from database events. Displays the parent  chain in order.</p> <p>Usage:</p> <pre><code>$ metaxy migrations status\n</code></pre>"},{"location":"reference/cli/#metaxy-migrations-list","title":"<code>metaxy migrations list</code>","text":"<p>List all migrations in chain order.</p> <p>Displays a simple table showing migration ID, creation time, and operations.</p> <p>Usage:</p> <pre><code>$ metaxy migrations list\n</code></pre>"},{"location":"reference/cli/#metaxy-migrations-explain","title":"<code>metaxy migrations explain</code>","text":"<p>Show detailed diff for a migration.</p> <p>Reads migration from YAML file. Computes and displays the GraphDiff between the two snapshots on-demand.</p> <p>Usage:</p> <pre><code>$ metaxy migrations explain [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>MIGRATION-ID, --migration-id</code>: Migration ID to explain (explains latest if not specified)</li> </ul>"},{"location":"reference/cli/#metaxy-migrations-describe","title":"<code>metaxy migrations describe</code>","text":"<p>Show verbose description of migration(s).</p> <p>Displays detailed information about what the migration will do: - Migration metadata (ID, parent, snapshots, created  timestamp) - Operations to execute - Affected features with row counts - Execution status if already run</p> <p>Usage:</p> <pre><code>$ metaxy migrations describe [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>MIGRATION-IDS, --migration-ids, --empty-migration-ids</code>: Migration IDs to describe (default: all migrations in order)  [default: []]</li> </ul>"},{"location":"reference/cli/#graph","title":"<code>graph</code>","text":"<p>Manage feature graphs</p> <p>Usage:</p> <pre><code>$ graph COMMAND\n</code></pre> <p>Commands:</p> <ul> <li><code>describe</code>: Describe a graph snapshot.</li> <li><code>history</code>: Show history of recorded graph snapshots.</li> <li><code>push</code>: Record all feature versions (push graph snapshot).</li> <li><code>render</code>: Render feature graph visualization.</li> </ul>"},{"location":"reference/cli/#metaxy-graph-push","title":"<code>metaxy graph push</code>","text":"<p>Record all feature versions (push graph snapshot).</p> <p>Records all features in the active graph to the metadata store with a deterministic snapshot version. This should be run after deploying new feature definitions.</p> <p>Usage:</p> <pre><code>$ metaxy graph push [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>STORE, --store</code>: Metadata store to use (defaults to configured default store)</li> </ul>"},{"location":"reference/cli/#metaxy-graph-history","title":"<code>metaxy graph history</code>","text":"<p>Show history of recorded graph snapshots.</p> <p>Displays all recorded graph snapshots from the metadata store, showing snapshot versions, when they were recorded, and  feature counts.</p> <p>Usage:</p> <pre><code>$ metaxy graph history [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>STORE, --store</code>: Metadata store to use (defaults to configured default store)</li> <li><code>LIMIT, --limit</code>: Limit number of snapshots to show (defaults to all)</li> </ul>"},{"location":"reference/cli/#metaxy-graph-describe","title":"<code>metaxy graph describe</code>","text":"<p>Describe a graph snapshot.</p> <p>Shows detailed information about a graph snapshot including: - Feature count - Graph depth (longest dependency chain) -  Root features (features with no dependencies)</p> <p>Usage:</p> <pre><code>$ metaxy graph describe [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>SNAPSHOT, --snapshot</code>: Snapshot version to describe (defaults to current graph from code)</li> <li><code>STORE, --store</code>: Metadata store to use (defaults to configured default store)</li> </ul>"},{"location":"reference/cli/#metaxy-graph-render","title":"<code>metaxy graph render</code>","text":"<p>Render feature graph visualization.</p> <p>Visualize the feature graph in different formats: - terminal: Terminal rendering with two types:</p> <pre><code>graph (default): Hierarchical tree view  cards: Panel/card-based view with dependency edges\n</code></pre> <p>\u2022 mermaid: Mermaid flowchart markup  \u2022 graphviz: Graphviz DOT format</p> <p>Usage:</p> <pre><code>$ metaxy graph render [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>SHOW-FIELDS, --show-fields, --no-show-fields</code>: Render configuration  [default: --show-fields]</li> <li><code>SHOW-FEATURE-VERSIONS, --show-feature-versions, --no-show-feature-versions</code>: Render configuration  [default: --show-feature-versions]</li> <li><code>SHOW-FIELD-VERSIONS, --show-field-versions, --no-show-field-versions</code>: Render configuration  [default: --show-field-versions]</li> <li><code>SHOW-CODE-VERSIONS, --show-code-versions, --no-show-code-versions</code>: Render configuration  [default: --no-show-code-versions]</li> <li><code>SHOW-SNAPSHOT-VERSION, --show-snapshot-version, --no-show-snapshot-version</code>: Render configuration  [default: --show-snapshot-version]</li> <li><code>HASH-LENGTH, --hash-length</code>: Render configuration  [default: 8]</li> <li><code>DIRECTION, --direction</code>: Render configuration  [default: TB]</li> <li><code>FEATURE, --feature</code>: Render configuration</li> <li><code>UP, --up</code>: Render configuration</li> <li><code>DOWN, --down</code>: Render configuration</li> <li><code>-f, --format</code>: Output format: terminal, mermaid, or graphviz  [default: terminal]</li> <li><code>-t, --type</code>: Terminal rendering type: graph or cards (only for --format terminal)  [choices: graph, cards] [default: graph]</li> <li><code>-o, --output</code>: Output file path (default: stdout)</li> <li><code>SNAPSHOT, --snapshot</code>: Snapshot version to render (default: current graph from code)</li> <li><code>STORE, --store</code>: Metadata store to use (for loading historical snapshots)</li> <li><code>MINIMAL, --minimal, --no-minimal</code>: Minimal output: only feature keys and dependencies  [default: --no-minimal]</li> <li><code>VERBOSE, --verbose, --no-verbose</code>: Verbose output: show all available information  [default: --no-verbose]</li> </ul>"},{"location":"reference/cli/#graph-diff","title":"<code>graph-diff</code>","text":"<p>Compare and visualize graph snapshots</p> <p>Usage:</p> <pre><code>$ graph-diff COMMAND\n</code></pre> <p>Commands:</p> <ul> <li><code>render</code>: Render merged graph visualization comparing two snapshots.</li> </ul>"},{"location":"reference/cli/#metaxy-graph-diff-render","title":"<code>metaxy graph-diff render</code>","text":"<p>Render merged graph visualization comparing two snapshots.</p> <p>Shows all features color-coded by status (added/removed/changed/unchanged). Uses the unified rendering system - same  renderers as 'metaxy graph render'.</p> <p>Special snapshot literals: - \"latest\": Most recent snapshot in the store - \"current\": Current graph state from code</p> <p>Output formats: - terminal: Hierarchical tree view (default) - cards: Panel/card-based view - mermaid: Mermaid flowchart diagram - graphviz: Graphviz DOT format</p> <p>Usage:</p> <pre><code>$ metaxy graph-diff render FROM-SNAPSHOT [ARGS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>FROM-SNAPSHOT</code>: First snapshot to compare (can be \"latest\", \"current\", or snapshot hash)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>TO-SNAPSHOT, --to-snapshot</code>: Second snapshot to compare (can be \"latest\", \"current\", or snapshot hash)  [default: current]</li> <li><code>STORE, --store</code>: Metadata store to use (defaults to configured default store)</li> <li><code>-f, --format</code>: Output format: terminal, cards, mermaid, graphviz, json, or yaml  [choices: terminal, cards, mermaid, graphviz, json, yaml] [default: terminal]</li> <li><code>-o, --output</code>: Output file path (default: stdout)</li> <li><code>SHOW-FIELDS, --show-fields, --no-show-fields</code>: Render configuration  [default: --show-fields]</li> <li><code>SHOW-FEATURE-VERSIONS, --show-feature-versions, --no-show-feature-versions</code>: Render configuration  [default: --show-feature-versions]</li> <li><code>SHOW-FIELD-VERSIONS, --show-field-versions, --no-show-field-versions</code>: Render configuration  [default: --show-field-versions]</li> <li><code>SHOW-CODE-VERSIONS, --show-code-versions, --no-show-code-versions</code>: Render configuration  [default: --no-show-code-versions]</li> <li><code>SHOW-SNAPSHOT-VERSION, --show-snapshot-version, --no-show-snapshot-version</code>: Render configuration  [default: --show-snapshot-version]</li> <li><code>HASH-LENGTH, --hash-length</code>: Render configuration  [default: 8]</li> <li><code>DIRECTION, --direction</code>: Render configuration  [default: TB]</li> <li><code>FEATURE, --feature</code>: Render configuration</li> <li><code>UP, --up</code>: Render configuration</li> <li><code>DOWN, --down</code>: Render configuration</li> <li><code>MINIMAL, --minimal, --no-minimal</code>: Minimal output: only feature keys and dependencies  [default: --no-minimal]</li> <li><code>VERBOSE, --verbose, --no-verbose</code>: Verbose output: show all available information  [default: --no-verbose]</li> </ul>"},{"location":"reference/cli/#list","title":"<code>list</code>","text":"<p>List Metaxy entities</p> <p>Usage:</p> <pre><code>$ list COMMAND\n</code></pre> <p>Commands:</p> <ul> <li><code>features</code>: List Metaxy features</li> </ul>"},{"location":"reference/cli/#metaxy-list-features","title":"<code>metaxy list features</code>","text":"<p>List Metaxy features</p> <p>Usage:</p> <pre><code>$ metaxy list features\n</code></pre>"},{"location":"reference/cli/#metadata","title":"<code>metadata</code>","text":"<p>Manage Metaxy metadata</p> <p>Usage:</p> <pre><code>$ metadata COMMAND\n</code></pre> <p>Commands:</p> <ul> <li><code>copy</code>: Copy metadata between stores.</li> <li><code>drop</code>: Drop metadata from a store.</li> </ul>"},{"location":"reference/cli/#metaxy-metadata-copy","title":"<code>metaxy metadata copy</code>","text":"<p>Copy metadata between stores.</p> <p>Copies metadata for specified features from one store to another, optionally using a historical version. Useful for: -  Migrating data between environments - Backfilling metadata - Copying specific feature versions</p> <p>Incremental Mode (default):     By default, performs an anti-join on sample_uid to skip rows that already exist in the destination for the same  snapshot_version. This prevents duplicate writes.  Disabling incremental (--no-incremental) may improve performance  when: - The destination store is empty or has no overlap with source - The destination store has eventual deduplication</p> <p>Usage:</p> <pre><code>$ metaxy metadata copy FROM TO [ARGS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>FROM</code>: Source store name (must be configured in metaxy.toml)  [required]</li> <li><code>TO</code>: Destination store name (must be configured in metaxy.toml)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>FEATURE, --feature, --empty-feature</code>: Feature key to copy (e.g., 'my_feature' or 'group/my_feature'). Can be repeated multiple times. If not specified, uses  --all-features.</li> <li><code>ALL-FEATURES, --all-features, --no-all-features</code>: Copy all features from source store  [default: --no-all-features]</li> <li><code>SNAPSHOT, --snapshot</code>: Snapshot version to copy (defaults to latest in source store). The snapshot_version is preserved in the destination.</li> <li><code>INCREMENTAL, --incremental, --no-incremental</code>: Use incremental copy (compare data_version to skip existing rows). Disable for better performance if destination is  empty or uses deduplication.  [default: --incremental]</li> </ul>"},{"location":"reference/cli/#metaxy-metadata-drop","title":"<code>metaxy metadata drop</code>","text":"<p>Drop metadata from a store.</p> <p>Removes metadata for specified features from the store. This is a destructive operation and requires --confirm flag.</p> <p>Useful for: - Cleaning up test data - Re-computing feature metadata from scratch - Removing obsolete features</p> <p>Usage:</p> <pre><code>$ metaxy metadata drop [ARGS]\n</code></pre> <p>Options:</p> <ul> <li><code>STORE, --store</code>: Store name to drop metadata from (defaults to configured default store)</li> <li><code>FEATURE, --feature, --empty-feature</code>: Feature key to drop (e.g., 'my_feature' or 'group/my_feature'). Can be repeated multiple times. If not specified, uses  --all-features.</li> <li><code>ALL-FEATURES, --all-features, --no-all-features</code>: Drop metadata for all features in the store  [default: --no-all-features]</li> <li><code>CONFIRM, --confirm, --no-confirm</code>: Confirm the drop operation (required to prevent accidental deletion)  [default: --no-confirm]</li> </ul>"},{"location":"reference/cli/#examples","title":"Examples","text":""},{"location":"reference/cli/#recording-a-graph-snapshot","title":"Recording a graph snapshot","text":"<pre><code># Push the current feature graph to the metadata store\nmetaxy graph push\n</code></pre> <p>The recommendation is to run this command in your CD pipeline.</p>"},{"location":"reference/cli/#generating-and-applying-migrations","title":"Generating and applying migrations","text":"<pre><code># Generate a migration for detected changes\nmetaxy migrations generate --op metaxy.migrations.ops.DataVersionReconciliation\n\n# Apply pending migrations\nmetaxy migrations apply\n</code></pre>"},{"location":"reference/cli/#visualizing-the-feature-graph","title":"Visualizing the feature graph","text":"<pre><code># Render as terminal tree view\nmetaxy graph render\n\n# Render as Mermaid diagram\nmetaxy graph render --format mermaid\n\n# Compare two snapshots\nmetaxy graph-diff render &lt;snapshot-id&gt; current --format mermaid\n</code></pre>"}]}